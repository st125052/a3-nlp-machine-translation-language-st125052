{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from app.classes.transformer.sequence_to_sequence_transformer import Seq2SeqTransformer\n",
    "from app.classes.transformer.decoder import Decoder\n",
    "from app.classes.transformer.encoder import Encoder\n",
    "from app.classes.transformer.decoder_layer import DecoderLayer\n",
    "from app.classes.transformer.encoder_layer import EncoderLayer\n",
    "from app.classes.transformer.multi_head_attention_layer import MultiHeadAttentionLayer\n",
    "from app.classes.transformer.position_wise_feed_forward_layer import PositionwiseFeedforwardLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") \n",
    "\n",
    "SRC_LANGUAGE = 'english'\n",
    "TRG_LANGUAGE = 'japanese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../helper/transformer/text_transform.pkl', 'rb') as f:\n",
    "    text_transform = dill.load(f)\n",
    "\n",
    "with open('../../app/models/transformer/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('../../app/models/transformer/vocab_transform.pkl', 'rb') as f:\n",
    "    vocab_transform = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sample_translation():\n",
    "    # Perform sample translation\n",
    "    src_text = text_transform[SRC_LANGUAGE](\"The weather is good today\").to(device)\n",
    "    trg_text = text_transform[TRG_LANGUAGE](\"鼻\").to(device)\n",
    "\n",
    "    src_text = src_text.reshape(1, -1)  #because batch_size is 1\n",
    "    trg_text = trg_text.reshape(1, -1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(src_text, trg_text) #turn off teacher forcing\n",
    "\n",
    "    output = output.squeeze(0)\n",
    "    output = output[1:]\n",
    "    output_max = output.argmax(1)\n",
    "    mapping = vocab_transform[TRG_LANGUAGE].get_itos()\n",
    "    print(\"Prediction: \", \"\".join([mapping[i] for i in output_max]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  からは\n"
     ]
    }
   ],
   "source": [
    "perform_sample_translation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
