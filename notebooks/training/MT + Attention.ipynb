{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Attention\n",
    "\n",
    "<img src=\"../figures/attention1.jpg\" width=\"800\">\n",
    "<img src=\"../figures/attention2.jpg\" width=\"800\">\n",
    "<img src=\"../figures/attention3.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math, time, random\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Verah/JParaCrawl-Filtered-English-Japanese-Parallel-Corpus\", split=\"train\").select(range(30000)).remove_columns([\"id\", \"model1_accepted\", \"model2_accepted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english': 'And everyone will not care that it is not you.',\n",
       " 'japanese': '鼻・口のところはあらかじめ少し切っておくといいですね。'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'english'\n",
    "TRG_LANGUAGE = 'japanese'\n",
    "\n",
    "data_list = [(item[SRC_LANGUAGE], item[TRG_LANGUAGE]) for item in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = type('CustomDataset', (Dataset,), {\n",
    "    '__len__': lambda self: len(data_list),\n",
    "    '__getitem__': lambda self, idx: data_list[idx]\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - (train_size + val_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('And everyone will not care that it is not you.',\n",
       " '鼻・口のところはあらかじめ少し切っておくといいですね。')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's take a look at one example of train\n",
    "sample = next(iter(dataset))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 29001 is plenty,, we gonna call `random_split` to train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(999)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = len(list(iter(val)))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = len(list(iter(test)))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download de_core_news_sm\n",
    "```\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='ja_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  And everyone will not care that it is not you.\n",
      "Tokenization:  ['And', 'everyone', 'will', 'not', 'care', 'that', 'it', 'is', 'not', 'you', '.']\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[0])\n",
    "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to tokenize our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
    "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[433, 19, 11, 0, 11]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see some example\n",
    "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visual'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 1891, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True,  collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, ja in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([81, 12])\n",
      "Japanese shape:  torch.Size([91, 12])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (seq len, batch_size)\n",
    "print(\"Japanese shape: \", ja.shape)   # (seq len, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqPackedAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device  = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        #src: [src len, batch_size]\n",
    "        mask = (src == self.src_pad_idx).permute(1, 0)  #permute so that it's the same shape as attention\n",
    "        #mask: [batch_size, src len] #(0, 0, 0, 0, 0, 1, 1)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        #src: [src len, batch_size]\n",
    "        #trg: [trg len, batch_size]\n",
    "        \n",
    "        #initialize something\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len    = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs    = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
    "        \n",
    "        #send our src text into encoder\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "        #encoder_outputs refer to all hidden states (last layer)\n",
    "        #hidden refer to the last hidden state (of each layer, of each direction)\n",
    "        \n",
    "        input_ = trg[0, :]\n",
    "        \n",
    "        mask   = self.create_mask(src) #(0, 0, 0, 0, 0, 1, 1)\n",
    "        \n",
    "        #for each of the input of the trg text\n",
    "        for t in range(1, trg_len):\n",
    "            #send them to the decoder\n",
    "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
    "            #output: [batch_size, output_dim] ==> predictions\n",
    "            #hidden: [batch_size, hid_dim]\n",
    "            #attention: [batch_size, src len]\n",
    "            \n",
    "            #append the output to a list\n",
    "            outputs[t] = output\n",
    "            attentions[t] = attention\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1          = output.argmax(1)  #autoregressive\n",
    "            \n",
    "            input_ = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn       = nn.GRU(emb_dim, hid_dim, bidirectional=True)\n",
    "        self.fc        = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.dropout   = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        #embedding\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #packed\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=False)\n",
    "        #rnn\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        #unpacked\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        #-1, -2 hidden state\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim = 1)))\n",
    "        \n",
    "        #outputs: [src len, batch_size, hid dim * 2]\n",
    "        #hidden:  [batch_size, hid_dim]\n",
    "        \n",
    "        return outputs, hidden\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "The attention used here is additive attention which is defined by:\n",
    "\n",
    "$$e = v\\text{tanh}(Uh + Ws + b)$$\n",
    "\n",
    "The `forward` method now takes a `mask` input. This is a `[batch size, source sentence length]` tensor that is 1 when the source sentence token is not a padding token, and 0 when it is a padding token. For example, if the source sentence is: `[\"hello\", \"how\", \"are\", \"you\", \"?\", `<pad>`, `<pad>`]`, then the mask would be `[1, 1, 1, 1, 1, 0, 0]`.\n",
    "\n",
    "We apply the mask after the attention has been calculated, but before it has been normalized by the `softmax` function. It is applied using `masked_fill`. This fills the tensor at each element where the first argument (`mask == 0`) is true, with the value given by the second argument (`-1e10`). In other words, it will take the un-normalized attention values, and change the attention values over padded elements to be `-1e10`. As these numbers will be miniscule compared to the other values they will become zero when passed through the `softmax` layer, ensuring no attention is payed to padding tokens in the source sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
    "        self.W = nn.Linear(hid_dim, hid_dim) #for decoder input_\n",
    "        self.U = nn.Linear(hid_dim * 2, hid_dim)  #for encoder_outputs\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        #hidden = [batch_size, hid_dim] ==> first hidden is basically the last hidden of the encoder\n",
    "        #encoder_outputs = [src len, batch_size, hid_dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len    = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat the hidden src len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        #hidden = [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        #permute the encoder_outputs just so that you can perform multiplication / addition\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #encoder_outputs = [batch_size, src_len, hid_dim * 2]\n",
    "        \n",
    "        #add\n",
    "        energy = self.v(torch.tanh(self.W(hidden) + self.U(encoder_outputs))).squeeze(2)\n",
    "        #(batch_size, src len, 1) ==> (batch_size, src len)\n",
    "        \n",
    "        #mask\n",
    "        energy = energy.masked_fill(mask, -1e10)\n",
    "        \n",
    "        return F.softmax(energy, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention  = attention\n",
    "        self.embedding  = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn        = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
    "        self.fc         = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
    "        self.dropout    = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "        #input: [batch_size]\n",
    "        #hidden: [batch_size, hid_dim]\n",
    "        #encoder_ouputs: [src len, batch_size, hid_dim * 2]\n",
    "        #mask: [batch_size, src len]\n",
    "                \n",
    "        #embed our input\n",
    "        input    = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch_size, emb_dim]\n",
    "        \n",
    "        #calculate the attention\n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "        #a = [batch_size, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        #a = [batch_size, 1, src len]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #encoder_ouputs: [batch_size, src len, hid_dim * 2]\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        #weighted: [batch_size, 1, hid_dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        #weighted: [1, batch_size, hid_dim * 2]\n",
    "        \n",
    "        #send the input to decoder rnn\n",
    "            #concatenate (embed, weighted encoder_outputs)\n",
    "            #[1, batch_size, emb_dim]; [1, batch_size, hid_dim * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        #rnn_input: [1, batch_size, emb_dim + hid_dim * 2]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "            \n",
    "        #send the output of the decoder rnn to fc layer to predict the word\n",
    "            #prediction = fc(concatenate (output, weighted, embed))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output   = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc(torch.cat((embedded, output, weighted), dim = 1))\n",
    "        #prediction: [batch_size, output_dim]\n",
    "            \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training\n",
    "\n",
    "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqPackedAttention(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9728, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(9301, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc): Linear(in_features=1792, out_features=9301, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "emb_dim     = 256  \n",
    "hid_dim     = 512  \n",
    "dropout     = 0.5\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "\n",
    "attn = Attention(hid_dim)\n",
    "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
    "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
    "\n",
    "model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490368\n",
      "393216\n",
      "786432\n",
      "  1536\n",
      "  1536\n",
      "393216\n",
      "786432\n",
      "  1536\n",
      "  1536\n",
      "524288\n",
      "   512\n",
      "   512\n",
      "262144\n",
      "   512\n",
      "524288\n",
      "   512\n",
      "2381056\n",
      "1966080\n",
      "786432\n",
      "  1536\n",
      "  1536\n",
      "16667392\n",
      "  9301\n",
      "______\n",
      "27981909\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss function calculates the average loss per token, however by passing the index of the `<pad>` token as the `ignore_index` argument we ignore the loss whenever the target token is a padding token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is very similar to part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_length, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, attentions = model(src, src_length, trg)\n",
    "        \n",
    "        #trg    = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        #the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg    = trg[1:].view(-1)\n",
    "        #trg    = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "        \n",
    "    #turn off dropout (and batch norm if used)\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_length, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg    = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg    = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 58m 55s\n",
      "Train Loss: 3.025 | Train PPL:  20.598\n",
      "Val. Loss: 2.673 |  Val. PPL:  14.479\n",
      "Epoch: 02 | Time: 46m 39s\n",
      "Train Loss: 1.813 | Train PPL:   6.131\n",
      "Val. Loss: 2.498 |  Val. PPL:  12.163\n",
      "Epoch: 03 | Time: 46m 22s\n",
      "Train Loss: 1.646 | Train PPL:   5.186\n",
      "Val. Loss: 2.295 |  Val. PPL:   9.922\n",
      "Epoch: 04 | Time: 46m 11s\n",
      "Train Loss: 1.488 | Train PPL:   4.430\n",
      "Val. Loss: 2.174 |  Val. PPL:   8.791\n",
      "Epoch: 05 | Time: 46m 9s\n",
      "Train Loss: 1.374 | Train PPL:   3.950\n",
      "Val. Loss: 2.130 |  Val. PPL:   8.414\n",
      "Epoch: 06 | Time: 46m 12s\n",
      "Train Loss: 1.241 | Train PPL:   3.460\n",
      "Val. Loss: 2.208 |  Val. PPL:   9.098\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     12\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, criterion, val_loader_length)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#for plotting\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[78], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, criterion, clip, loader_length)\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, src_length, trg \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      8\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m     trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:47\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[66], line 29\u001b[0m, in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     27\u001b[0m     processed_text \u001b[38;5;241m=\u001b[39m text_transform[SRC_LANGUAGE](src_sample\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     28\u001b[0m     src_batch\u001b[38;5;241m.\u001b[39mappend(processed_text)\n\u001b[1;32m---> 29\u001b[0m     trg_batch\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtext_transform\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTRG_LANGUAGE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m     src_len_batch\u001b[38;5;241m.\u001b[39mappend(processed_text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     32\u001b[0m src_batch \u001b[38;5;241m=\u001b[39m pad_sequence(src_batch, padding_value\u001b[38;5;241m=\u001b[39mPAD_IDX)\n",
      "Cell \u001b[1;32mIn[66], line 5\u001b[0m, in \u001b[0;36msequential_transforms.<locals>.func\u001b[1;34m(txt_input)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(txt_input):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[1;32m----> 5\u001b[0m         txt_input \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m txt_input\n",
      "Cell \u001b[1;32mIn[66], line 11\u001b[0m, in \u001b[0;36mtensor_transform\u001b[1;34m(token_ids)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtensor_transform\u001b[39m(token_ids):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSOS_IDX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[0;32m     12\u001b[0m                       torch\u001b[38;5;241m.\u001b[39mtensor(token_ids), \n\u001b[0;32m     13\u001b[0m                       torch\u001b[38;5;241m.\u001b[39mtensor([EOS_IDX])))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 50\n",
    "clip       = 1\n",
    "\n",
    "save_path = f'../../app/models/attention/{model.__class__.__name__}.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.101 | Test PPL:   8.175 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqPackedAttention(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9728, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(9301, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc): Linear(in_features=1792, out_features=9301, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And everyone will not care that it is not you.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'鼻・口のところはあらかじめ少し切っておくといいですね。'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  306,  656,   54,   90, 1520,   28,   37,   19,   90,   17,    5,\n",
       "           3], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2, 3969,   64,  823,    4, 1097,   10, 2470, 1072, 2666,    9, 1091,\n",
       "          13,  300,   27, 1038,    8,    3], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(-1, 1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 1]), torch.Size([18, 1]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, text_length, trg_text, 0) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 1, 9301])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #trg_len, batch_size, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 9301])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 9301])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3969, 1771,    9,   42,    4,   10,    5,   10, 1072,   14,   63,    8,\n",
       "           3,    3,    3,    3,   76], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鼻\n",
      "置い\n",
      "て\n",
      "いる\n",
      "の\n",
      "は\n",
      "、\n",
      "は\n",
      "少し\n",
      "で\n",
      "ください\n",
      "。\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "<eos>\n",
      "ませ\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Attention\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 1, 13])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'And',\n",
       " 'everyone',\n",
       " 'will',\n",
       " 'not',\n",
       " 'care',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'you',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '鼻',\n",
       " '置い',\n",
       " 'て',\n",
       " 'いる',\n",
       " 'の',\n",
       " 'は',\n",
       " '、',\n",
       " 'は',\n",
       " '少し',\n",
       " 'で',\n",
       " 'ください',\n",
       " '。',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " 'ませ']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swara\\AppData\\Local\\Temp\\ipykernel_7208\\140266900.py:15: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "C:\\Users\\swara\\AppData\\Local\\Temp\\ipykernel_7208\\140266900.py:16: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(y_ticks)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 40763 (\\N{CJK UNIFIED IDEOGRAPH-9F3B}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12390 (\\N{HIRAGANA LETTER TE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12427 (\\N{HIRAGANA LETTER RU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12399 (\\N{HIRAGANA LETTER HA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 23569 (\\N{CJK UNIFIED IDEOGRAPH-5C11}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12391 (\\N{HIRAGANA LETTER DE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12367 (\\N{HIRAGANA LETTER KU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12384 (\\N{HIRAGANA LETTER DA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12373 (\\N{HIRAGANA LETTER SA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12414 (\\N{HIRAGANA LETTER MA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\swara\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 12379 (\\N{HIRAGANA LETTER SE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attentions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
